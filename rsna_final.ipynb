{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Setup","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport re\nfrom tqdm import tqdm_notebook as tqdm\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import functional\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport cv2\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import model_selection\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.optim.lr_scheduler import StepLR\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-29T02:17:32.095129Z","iopub.execute_input":"2021-09-29T02:17:32.095568Z","iopub.status.idle":"2021-09-29T02:17:32.104396Z","shell.execute_reply.started":"2021-09-29T02:17:32.095524Z","shell.execute_reply":"2021-09-29T02:17:32.103478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# local notebook settings\n# from efficientnet_pytorch_3d import EfficientNet3D\n# train_path = 'train_labels.csv'\n# test_path = 'sample_submission_csv'\n# png_path = 'archive'\n# from volumentations import *\n\n\n# kaggle settings\nimport sys\nsys.path.append('../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D')\nsys.path.append('../input/3d-augmentation/volumentations-master')\nsys.path.append('../input/gradualwarmupschedulerv2')\nsys.path.append('../input/medicalnet')\n\nimport sys\nfrom volumentations import *\nfrom efficientnet_pytorch_3d import EfficientNet3D\nfrom warmup_scheduler import GradualWarmupScheduler\nfrom models import resnet\nfrom model import generate_model\n\ntrain_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv'\ntest_path = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv'\npng_path = '../input/rsna-miccai-png'","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.111803Z","iopub.execute_input":"2021-09-29T02:17:32.11356Z","iopub.status.idle":"2021-09-29T02:17:32.130514Z","shell.execute_reply.started":"2021-09-29T02:17:32.11352Z","shell.execute_reply":"2021-09-29T02:17:32.129259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(38)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.1358Z","iopub.execute_input":"2021-09-29T02:17:32.138305Z","iopub.status.idle":"2021-09-29T02:17:32.222777Z","shell.execute_reply.started":"2021-09-29T02:17:32.13827Z","shell.execute_reply":"2021-09-29T02:17:32.221911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 256\nnum_img = 64\nmri_types = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]\n# # mri_types = [\"FLAIR\", \"T1w\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.227391Z","iopub.execute_input":"2021-09-29T02:17:32.229554Z","iopub.status.idle":"2021-09-29T02:17:32.2358Z","shell.execute_reply.started":"2021-09-29T02:17:32.229514Z","shell.execute_reply":"2021-09-29T02:17:32.234397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adapt from the original file \nimport argparse\n\ndef parse_opts():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--data_root',\n        default='./data',\n        type=str,\n        help='Root directory path of data')\n    parser.add_argument(\n        '--img_list',\n        default='./data/train.txt',\n        type=str,\n        help='Path for image list file')\n    parser.add_argument(\n        '--n_seg_classes',\n        default=2,\n        type=int,\n        help=\"Number of segmentation classes\"\n    )\n    parser.add_argument(\n        '--learning_rate',  # set to 0.001 when finetune\n        default=0.001,\n        type=float,\n        help=\n        'Initial learning rate (divided by 10 while training by lr scheduler)')\n    parser.add_argument(\n        '--num_workers',\n        default=4,\n        type=int,\n        help='Number of jobs')\n    parser.add_argument(\n        '--batch_size', default=1, type=int, help='Batch Size')\n    parser.add_argument(\n        '--phase', default='train', type=str, help='Phase of train or test')\n    parser.add_argument(\n        '--save_intervals',\n        default=10,\n        type=int,\n        help='Interation for saving model')\n    parser.add_argument(\n        '--n_epochs',\n        default=200,\n        type=int,\n        help='Number of total epochs to run')\n    parser.add_argument(\n        '--input_D',\n    default=64,\n        type=int,\n        help='Input size of depth')\n    parser.add_argument(\n        '--input_H',\n        default=256,\n        type=int,\n        help='Input size of height')\n    parser.add_argument(\n        '--input_W',\n        default=256,\n        type=int,\n        help='Input size of width')\n    parser.add_argument(\n        '--resume_path',\n        default='',\n        type=str,\n        help=\n        'Path for resume model.'\n    )\n    parser.add_argument(\n        '--pretrain_path',\n        default='pretrain/resnet_50.pth',\n        type=str,\n        help=\n        'Path for pretrained model.'\n    )\n    parser.add_argument(\n        '--new_layer_names',\n        #default=['upsample1', 'cmp_layer3', 'upsample2', 'cmp_layer2', 'upsample3', 'cmp_layer1', 'upsample4', 'cmp_conv1', 'conv_seg'],\n        default=['conv_seg'],\n        type=list,\n        help='New layer except for backbone')\n    parser.add_argument(\n        '--no_cuda', action='store_true', help='If true, cuda is not used.')\n    parser.set_defaults(no_cuda=False)\n    parser.add_argument(\n        '--gpu_id',\n        nargs='+',\n        type=int,              \n        help='Gpu id lists')\n    parser.add_argument(\n        '--model',\n        default='resnet',\n        type=str,\n        help='(resnet | preresnet | wideresnet | resnext | densenet | ')\n    parser.add_argument(\n        '--model_depth',\n        default=50,\n        type=int,\n        help='Depth of resnet (10 | 18 | 34 | 50 | 101)')\n    parser.add_argument(\n        '--resnet_shortcut',\n        default='B',\n        type=str,\n        help='Shortcut type of resnet (A | B)')\n    parser.add_argument(\n        '--manual_seed', default=38, type=int, help='Manually set random seed')\n    parser.add_argument(\n        '--ci_test', action='store_true', help='If true, ci testing is used.')\n    args = parser.parse_args([])\n    args.save_folder = \"./trails/models/{}_{}\".format(args.model, args.model_depth)\n    \n    return args","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.240173Z","iopub.execute_input":"2021-09-29T02:17:32.242404Z","iopub.status.idle":"2021-09-29T02:17:32.26326Z","shell.execute_reply.started":"2021-09-29T02:17:32.242366Z","shell.execute_reply":"2021-09-29T02:17:32.262389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opts = parse_opts()   \nopts.n_epochs = 15\nopts.no_cuda = False if torch.cuda.is_available() else True\n# opts.pretrain_path = '../input/medicalnet/pretrain/resnet_50_23dataset.pth'\nopts.pretrain_path = ''\nopts.model_depth = 10\nopts.resnet_shortcut = 'B'\nopts.input_D = 64\nopts.input_H = 256\nopts.input_W = 256\nopts.gpu_id = [1] if torch.cuda.is_available() else []\nopts.batch_size = 4\nopts.n_seg_classes = 1\n\ndevice = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.267959Z","iopub.execute_input":"2021-09-29T02:17:32.270284Z","iopub.status.idle":"2021-09-29T02:17:32.281917Z","shell.execute_reply.started":"2021-09-29T02:17:32.270227Z","shell.execute_reply":"2021-09-29T02:17:32.280992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Dataloader","metadata":{}},{"cell_type":"code","source":"def load_image(scan_id, mri_type, split='train', path=png_path):\n    mri = sorted(glob.glob(f\"{path}/{split}/{scan_id}/{mri_type}/*.png\"), \n                 key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n    \n    if len(mri) == 0:\n        i_img = np.zeros((img_size, img_size, num_img))\n    elif len(mri) < num_img:\n        i_img = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (img_size, img_size))\n                        for path in mri[0:num_img]]).T \n        num_zero = num_img - i_img.shape[-1]\n        i_img.shape[-1]\n        i_img = np.concatenate((i_img, np.zeros((img_size, img_size, num_zero))), -1)\n    else: \n        i_img = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (img_size, img_size)) \n                         for path in mri[len(mri) // 2 - num_img // 2: len(mri) // 2 + num_img // 2]]).T\n            \n    return i_img","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.285835Z","iopub.execute_input":"2021-09-29T02:17:32.287863Z","iopub.status.idle":"2021-09-29T02:17:32.299461Z","shell.execute_reply.started":"2021-09-29T02:17:32.287778Z","shell.execute_reply":"2021-09-29T02:17:32.298659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def npy_loader(brat, mri_type, mode):\n    if mode == \"train\":\n        path = f\"../input/rsna-processed-voxels-64x256x256-clahe/voxels/{mri_type}/{brat}.npy\"\n    else: \n        path = f\"../input/rsnaprocessedvoxels64x256x256clahetrain/voxels/{mri_type}/{brat}.npy\"\n    \n    return np.load(path)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.304012Z","iopub.execute_input":"2021-09-29T02:17:32.306521Z","iopub.status.idle":"2021-09-29T02:17:32.312527Z","shell.execute_reply.started":"2021-09-29T02:17:32.306481Z","shell.execute_reply":"2021-09-29T02:17:32.311712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RSNADataset(Dataset):\n    def __init__(self, csv, mri_type, mode='train', transform=None):\n        self.csv = csv\n        self.mode = mode\n        self.transform = transform\n        self.mri_type = mri_type\n        \n    def __len__(self): \n        return self.csv.shape[0]\n    \n    def __getitem__(self, idx): \n        data = self.csv.iloc[idx]\n        brat = str(int(data[\"BraTS21ID\"])).zfill(5)\n        mgmt = data['MGMT_value']\n        \n        image = npy_loader(brat, self.mri_type, self.mode)\n#         image = torch.tensor(image, dtype=torch.float32)\n#         image = load_image(brat, self.mri_type, split='train')\n\n        image = image.transpose(1, 2, 0)           \n    \n        if self.transform is not None:\n            data = {'image': image}\n            aug_data = self.transform(**data)\n            image = aug_data['image']\n            \n        image = image.transpose(2, 0, 1)           \n        image = image / 255\n        \n        if self.mode == 'train': \n            return torch.tensor(image, dtype=torch.float32), torch.tensor(mgmt, dtype=torch.float)\n        else: \n            return torch.tensor(image, dtype=torch.float32), brat\n                ","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.318649Z","iopub.execute_input":"2021-09-29T02:17:32.320617Z","iopub.status.idle":"2021-09-29T02:17:32.333054Z","shell.execute_reply.started":"2021-09-29T02:17:32.320582Z","shell.execute_reply":"2021-09-29T02:17:32.332073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms_train = Compose([\n        ElasticTransformPseudo2D(alpha=360, sigma=360 * 0.05, alpha_affine=360 * 0.03, p=0.3),\n        RotatePseudo2D(axes=(0,1), limit=(-30, 30), p=0.5),\n        Flip(1, p=0.4)\n    ], p=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.337971Z","iopub.execute_input":"2021-09-29T02:17:32.340448Z","iopub.status.idle":"2021-09-29T02:17:32.347407Z","shell.execute_reply.started":"2021-09-29T02:17:32.340382Z","shell.execute_reply":"2021-09-29T02:17:32.346561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # for testing the cell below\n\n# train_df = pd.read_csv(train_path)\n# df_train, df_val = model_selection.train_test_split(train_df, test_size=0.2, random_state=38, stratify=train_df[\"MGMT_value\"])\n# df_train = df_train.loc[(df_train['BraTS21ID'] != 109) & (df_train['BraTS21ID'] != 123) & (df_train['BraTS21ID'] != 709), :]\n# train_dataset = RSNADataset(df_train, mri_types[0], transform=transforms_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.351646Z","iopub.execute_input":"2021-09-29T02:17:32.35384Z","iopub.status.idle":"2021-09-29T02:17:32.358657Z","shell.execute_reply.started":"2021-09-29T02:17:32.353796Z","shell.execute_reply":"2021-09-29T02:17:32.357863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # creates animation to check the dataset\n\n# from matplotlib import animation, rc\n# rc('animation', html='jshtml')\n\n\n# def create_animation(ims):\n#     fig = plt.figure(figsize=(3, 3))\n#     plt.axis('off')\n#     im = plt.imshow(ims[0], cmap=\"gray\")\n\n#     def animate_func(i):\n#         im.set_array(ims[i])\n#         return [im]\n\n#     return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//24)\n\n# test = train_dataset.__getitem__(1)\n# create_animation(test[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.363151Z","iopub.execute_input":"2021-09-29T02:17:32.365524Z","iopub.status.idle":"2021-09-29T02:17:32.370758Z","shell.execute_reply.started":"2021-09-29T02:17:32.365487Z","shell.execute_reply":"2021-09-29T02:17:32.369983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create_animation(test[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.374324Z","iopub.execute_input":"2021-09-29T02:17:32.375832Z","iopub.status.idle":"2021-09-29T02:17:32.381186Z","shell.execute_reply.started":"2021-09-29T02:17:32.375778Z","shell.execute_reply":"2021-09-29T02:17:32.379862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Model","metadata":{}},{"cell_type":"code","source":"# EfficientNet3D \nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n        \n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.383582Z","iopub.execute_input":"2021-09-29T02:17:32.384722Z","iopub.status.idle":"2021-09-29T02:17:32.389971Z","shell.execute_reply.started":"2021-09-29T02:17:32.384683Z","shell.execute_reply":"2021-09-29T02:17:32.389165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MedicalNet\nclass Model(nn.Module):\n    def __init__(self, model_name, opts):\n        super().__init__()\n        self.model_name = model_name\n        self.medical_net, parameters = generate_model(opts)\n#         self.drop_in = nn.Dropout(p=0.1)\n        self.pool = nn.AdaptiveAvgPool3d(1)\n        \n        if opts.pretrain_path:\n            self.init_model()\n            \n    def forward(self, x):\n#         x = self.medical_net(self.drop_in(x))\n        x = self.medical_net(x)\n        x = self.pool(x)        \n        return x\n    \n    def init_model(self):\n        net_dict = self.medical_net.state_dict()\n        pretrain = torch.load(f'../input/medicalnet/pretrain/{self.model_name}.pth', \n                              map_location=device)\n        pretrain_dict = {k: v for k, v in pretrain['state_dict'].items() if k in net_dict.keys()}\n        net_dict.update(pretrain_dict)\n        self.medical_net.load_state_dict(net_dict)\n        print(\"loaded pretrained weights\")","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.392636Z","iopub.execute_input":"2021-09-29T02:17:32.393757Z","iopub.status.idle":"2021-09-29T02:17:32.415251Z","shell.execute_reply.started":"2021-09-29T02:17:32.393722Z","shell.execute_reply":"2021-09-29T02:17:32.414307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model('resnet_50_23dataset', opts)\ncount = 0\ncol = [30, 31, 32, 69, 70, 71, 126, 127, 128, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166]\n\nfor name, param in model.named_parameters():\n#     if param.requires_grad and (count < 160):\n    if param.requires_grad and (count not in col):\n        param.requires_grad = False\n    print(name, param.requires_grad)\n    count += 1\n\nmodel = Model('resnet_10_23dataset', opts)\ncount = 0\n\nfor name, param in model.named_parameters():\n    if param.requires_grad and (count < 36):\n        param.requires_grad = False\n    print(name, param.requires_grad)\n    count += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.419806Z","iopub.execute_input":"2021-09-29T02:17:32.420874Z","iopub.status.idle":"2021-09-29T02:17:32.429318Z","shell.execute_reply.started":"2021-09-29T02:17:32.420777Z","shell.execute_reply":"2021-09-29T02:17:32.428531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Train ","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, mri_type, model, criterion, optimizer, scheduler, device):\n        self.mri_type = mri_type\n        self.model = model\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.device = device\n        self.model_train_losses = []\n        self.model_val_losses = []\n        self.model_val_auc = []\n        \n    def fit(self, train_loader, val_loader, n_epochs):\n        best_val = 10\n\n        for epoch in range(n_epochs): \n            self.scheduler.step() \n            \n            # train\n            avg_train = self.train_epoch(train_loader)\n            self.model_train_losses.append(avg_train)\n            \n            print(f'epoch {epoch + 1} train: {avg_train:.3f}')\n                \n            # val\n            avg_val, auc = self.val_epoch(val_loader)\n            \n            self.model_val_losses.append(avg_val)\n            self.model_val_auc.append(auc)\n            print(f'epoch {epoch + 1} val: {avg_val:.3f}, auc: {auc:.3f}')\n\n            if avg_val < best_val: \n                print('save model ...')\n                best_val = avg_val\n                last_model =  f'{self.mri_type}-e{epoch + 1}-loss{avg_val:.3f}-auc{auc:.3f}.pt'\n                torch.save(self.model.state_dict(), f'{self.mri_type}-e{epoch + 1}-loss{avg_val:.3f}-auc{auc:.3f}.pt')\n\n            print('\\n\\n')\n            \n        return last_model\n                    \n    def train_epoch(self, train_loader):\n        train_loss = []\n        self.model.train()\n\n        for i, data in tqdm(enumerate(train_loader, 0)): \n            x, y = data\n            x = torch.unsqueeze(x, dim=1)\n            x, y = x.to(device), y.to(device)\n            self.optimizer.zero_grad()\n\n            outputs = self.model(x).squeeze(1).view(-1)\n            loss = self.criterion(outputs, y)\n            loss.backward()\n            self.optimizer.step()\n\n            train_loss.append(loss.detach().item())\n        avg_train = sum(train_loss) / len(train_loss)\n        \n        return avg_train\n\n        \n    def val_epoch(self, val_loader):\n        self.model.eval()\n        outputs_all = []\n        y_all = []\n        val_loss = []    \n\n        for i, data in tqdm(enumerate(val_loader, 0)): \n            with torch.no_grad():\n                x, y = data \n                x = torch.unsqueeze(x, dim=1)\n                x, y = x.to(device), y.to(device)\n\n                outputs = self.model(x).squeeze(1).view(-1)\n                loss = self.criterion(outputs, y)\n                \n                outputs = torch.sigmoid(outputs)\n                outputs_all.extend(outputs.tolist())\n                y_all.extend(y.tolist())\n                val_loss.append(loss.detach().item())      \n        avg_val = sum(val_loss) / len(val_loss)\n        auc = roc_auc_score(y_all, outputs_all)\n        \n        return avg_val, auc","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.431748Z","iopub.execute_input":"2021-09-29T02:17:32.432323Z","iopub.status.idle":"2021-09-29T02:17:32.462627Z","shell.execute_reply.started":"2021-09-29T02:17:32.432288Z","shell.execute_reply":"2021-09-29T02:17:32.461754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.4644Z","iopub.execute_input":"2021-09-29T02:17:32.465017Z","iopub.status.idle":"2021-09-29T02:17:32.474928Z","shell.execute_reply.started":"2021-09-29T02:17:32.464983Z","shell.execute_reply":"2021-09-29T02:17:32.474025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ndf_train, df_val = model_selection.train_test_split(train_df, test_size=0.2, random_state=38, stratify=train_df[\"MGMT_value\"])\ndf_train = df_train.loc[(df_train['BraTS21ID'] != 109) & (df_train['BraTS21ID'] != 123) & (df_train['BraTS21ID'] != 709), :]","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.476551Z","iopub.execute_input":"2021-09-29T02:17:32.477157Z","iopub.status.idle":"2021-09-29T02:17:32.529525Z","shell.execute_reply.started":"2021-09-29T02:17:32.477121Z","shell.execute_reply":"2021-09-29T02:17:32.528677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cosine_epo = 12\nwarmup_epo = 3\nn_epochs = cosine_epo + warmup_epo\n\nmodels = []\nmodels_fields = []\n\nfor mri_type in mri_types: \n    model = Model('resnet_10_23dataset', opts)\n    count = 0\n\n#     for name, param in model.named_parameters():\n#         if param.requires_grad and (count < 36):\n#             param.requires_grad = False\n#         count += 1\n        \n    criterion = functional.binary_cross_entropy_with_logits\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    scheduler = StepLR(optimizer, step_size=8, gamma=0.1)\n\n#     optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n\n#     scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, cosine_epo)\n#     scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n\n    device = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    train_dataset = RSNADataset(df_train, mri_type, transform=transforms_train)\n    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=4, num_workers=4)\n\n    val_dataset = RSNADataset(df_val, mri_type)\n    val_loader = DataLoader(val_dataset, shuffle=False, batch_size=4, num_workers=4)\n\n#     mri_trainer = Trainer(mri_type, model, criterion, optimizer, scheduler_warmup, device)\n    scheduler_warmup=None\n    mri_trainer = Trainer(mri_type, model, criterion, optimizer, scheduler, device)\n\n    last_best_model = mri_trainer.fit(train_loader, val_loader, n_epochs)\n    \n    models.append(last_best_model)\n    models_fields.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:17:32.533612Z","iopub.execute_input":"2021-09-29T02:17:32.534122Z","iopub.status.idle":"2021-09-29T02:17:32.543296Z","shell.execute_reply.started":"2021-09-29T02:17:32.534084Z","shell.execute_reply":"2021-09-29T02:17:32.542099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Predict","metadata":{}},{"cell_type":"code","source":"device = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\n\ndf_test = pd.read_csv(test_path)\n\nwrite = 0\nmodels = [\"../input/best-loss-version5/FLAIR-e14-loss0.666-auc0.635.pt\",\n         \"../input/best-loss-version5/T1w-e13-loss0.671-auc0.650.pt\",\n         \"../input/best-loss-version5/T1wCE-e15-loss0.679-auc0.589.pt\",\n         \"../input/best-loss-version5/T2w-e15-loss0.664-auc0.654.pt\"]\n\nmri_types = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]\n\nfor trained_model in range(len(models)): \n    model = Model('resnet_10_23dataset', opts)\n    model.to(device)\n    checkpoint = torch.load(models[trained_model])\n    model.load_state_dict(checkpoint)\n    model.eval()\n    \n    test_dataset = RSNADataset(df_test, mri_type=mri_types[trained_model], mode=\"test\")\n    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)\n    \n    y_pred = []\n\n    for e, batch in enumerate(test_loader):\n        print(f\"{e + 1}/{len(test_loader)}\", end=\"\\r\")\n        \n        batch, brat = batch\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(batch.to(device).unsqueeze(1)).view(-1)).squeeze()\n            y_pred.extend(tmp_pred.tolist())\n    \n    y_pred = np.array(y_pred)\n    \n    if write == 0:\n        write = 1\n        submission = pd.DataFrame({\"BraTS21ID\": df_test['BraTS21ID'].apply(lambda x: str(x).zfill(5)), \"MGMT_value\": y_pred})\n    else: \n        submission['MGMT_value'] += y_pred\n\nsubmission['MGMT_value'] /= len(models)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-29T02:17:32.549121Z","iopub.execute_input":"2021-09-29T02:17:32.549899Z","iopub.status.idle":"2021-09-29T02:18:11.593624Z","shell.execute_reply.started":"2021-09-29T02:17:32.549862Z","shell.execute_reply":"2021-09-29T02:18:11.592676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T02:18:11.595207Z","iopub.execute_input":"2021-09-29T02:18:11.595566Z","iopub.status.idle":"2021-09-29T02:18:11.605057Z","shell.execute_reply.started":"2021-09-29T02:18:11.595524Z","shell.execute_reply":"2021-09-29T02:18:11.604217Z"},"trusted":true},"execution_count":null,"outputs":[]}]}